{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os\n",
    "import glob\n",
    "import tqdm\n",
    "import json\n",
    "import librosa\n",
    "from librosa import display\n",
    "from pathlib import Path\n",
    "import IPython.display as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['compressed_wav', 'uncompr_wav']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "## Create Config for preprocessing and pipeline parameters\n",
    "\n",
    "config = {'sr': 44100, \n",
    "          'audio_length': 1,\n",
    "          'mono': False,\n",
    "          'n_mels': 64,\n",
    "          'n_fft': 2048,\n",
    "          'hop_length': 256,\n",
    "          'win_length': 2048,\n",
    "          'window': 'hann',\n",
    "          'center': True,\n",
    "          'pad_mode': 'reflect',\n",
    "          'power': 2.0,\n",
    "         }\n",
    "\n",
    "# save classes from foldernames\n",
    "folders = glob.glob('_data/*_wav/')\n",
    "classes = sorted(set([Path(f).parts[-1] for f in folders]))\n",
    "config['classes'] = classes\n",
    "\n",
    "# save number of frames from length in samples divided by fft hop length\n",
    "config['n_frames'] = int(config['sr']*config['audio_length']/config['hop_length']) + 1\n",
    "\n",
    "# save input shape for model\n",
    "config['input_shape'] = (config['n_mels'], config['n_frames'], 1)\n",
    "\n",
    "# save config \n",
    "with open('DLNet_config.json', 'w+') as fp:\n",
    "    json.dump(config, fp, sort_keys=True, indent=4)\n",
    "\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate mel-filter matrix\n",
    "mel_filter = librosa.filters.mel(config['sr'], \n",
    "                                 config['n_fft'], \n",
    "                                 n_mels=config['n_mels'], \n",
    "                                 fmin=0.0, \n",
    "                                 fmax=None, \n",
    "                                 htk=False, \n",
    "                                 norm='slaney', \n",
    "                                 dtype=np.float32)\n",
    "\n",
    "\n",
    "# Groundtruth extraction from folder name\n",
    "def folder_name_to_one_hot(file_path):\n",
    "    \n",
    "    label = Path(file_path).parts[-2]\n",
    "    label_idx = classes.index(label)\n",
    "    \n",
    "    # get one hot encoded array\n",
    "    one_hot = tf.one_hot(label_idx, len(config['classes']), on_value=None, off_value=None, \n",
    "                         axis=None, dtype=tf.uint8, name=None)\n",
    "    return one_hot\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    # path string is saved as byte array in tf.data.dataset -> convert back to str\n",
    "    if type(file_path) is not str:\n",
    "        file_path = file_path.numpy()\n",
    "        file_path = file_path.decode('utf-8')\n",
    "    \n",
    "    \n",
    "    # load audio data \n",
    "    y, _ = librosa.core.load(file_path, sr=config['sr'], mono=config['mono'], offset=0.0, duration=None, \n",
    "                             dtype=np.float32, res_type='kaiser_best')\n",
    "\n",
    "    # calculate stft from audio data\n",
    "    stft = librosa.core.stft(y, n_fft=config['n_fft'], hop_length=config['hop_length'], \n",
    "                             win_length=config['win_length'], window=config['window'], \n",
    "                             center=config['center'], dtype=np.complex64, pad_mode=config['pad_mode'])\n",
    "\n",
    "    # filter stft with mel-filter\n",
    "    mel_spec = mel_filter.dot(np.abs(stft).astype(np.float32) ** config['power'])\n",
    "    \n",
    "    # add channel dimension for conv layer compatibility\n",
    "    mel_spec = np.expand_dims(mel_spec, axis=-1)\n",
    "    \n",
    "    # get ground truth from file_path string\n",
    "    one_hot = folder_name_to_one_hot(file_path)\n",
    "    \n",
    "    return mel_spec, one_hot\n",
    "\n",
    "# there is a TF bug where we get an error if the size of the tensor from a py.function is not set manualy\n",
    "# when called from a map()-function.\n",
    "def preprocessing_wrapper(file_path):\n",
    "    mel_spec, one_hot = tf.py_function(load_and_preprocess_data, [file_path], [tf.float32, tf.uint8])\n",
    "    \n",
    "    mel_spec.set_shape([config['n_mels'], config['n_frames'], 1])\n",
    "    one_hot.set_shape([len(config['classes'])])\n",
    "    return mel_spec, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Online preprocessing -> wav's are read, processed and a dataset is created on the fly (possibly sucky performance)\n",
    "\n",
    "# # autotune computation (performance optimization)\n",
    "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# # folder with the training data\n",
    "# train_files = '_data/train/*/*.wav'\n",
    "\n",
    "# # define a dataset of file paths\n",
    "# train_dataset = tf.data.Dataset.list_files(train_files)\n",
    "# # run the preprocessing via map\n",
    "# train_dataset = train_dataset.map(preprocessing_wrapper, num_parallel_calls=AUTOTUNE)\n",
    "# # shuffle the data\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=4000)\n",
    "# # batch examples\n",
    "# train_dataset = train_dataset.batch(64)\n",
    "# # prefetch\n",
    "# train_dataset = train_dataset.prefetch(AUTOTUNE)\n",
    "\n",
    "\n",
    "# # folder with the evaluation data\n",
    "# test_files = '_data/test/*/*.wav'\n",
    "\n",
    "# # define a dataset of file paths\n",
    "# test_dataset = tf.data.Dataset.list_files(test_files)\n",
    "# # run the preprocessing via map\n",
    "# test_dataset = test_dataset.map(preprocessing_wrapper, num_parallel_calls=AUTOTUNE)\n",
    "# # batch examples\n",
    "# test_dataset = test_dataset.batch(64)\n",
    "# # prefetch\n",
    "# test_dataset = test_dataset.prefetch(AUTOTUNE)\n",
    "\n",
    "# # create model architecture\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.Input(shape=config['input_shape']))\n",
    "# model.add(tf.keras.layers.BatchNormalization())\n",
    "# model.add(tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "# model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(tf.keras.layers.GaussianDropout(0.25))\n",
    "# model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "# model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "# model.add(tf.keras.layers.GaussianDropout(0.25))\n",
    "# model.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "# model.add(tf.keras.layers.GlobalMaxPool2D())\n",
    "# model.add(tf.keras.layers.Dense(len(config['classes']), activation=\"sigmoid\"))\n",
    "# model.summary()\n",
    "\n",
    "# # compile model\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # fit model\n",
    "# model.fit(train_dataset, epochs=10)\n",
    "# model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(TensorSpec(shape=(64, 517, 1), dtype=tf.float32, name=None), TensorSpec(shape=(2,), dtype=tf.uint8, name=None))\n"
     ]
    }
   ],
   "source": [
    "# Offline preprocessing -> ability to save preprocessed dataset tensors on harddrive\n",
    "\n",
    "# autotune computation\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "# folder with the training data\n",
    "train_files = '_data/.train/*/*.wav'\n",
    "# define a dataset of file paths\n",
    "train_dataset = tf.data.Dataset.list_files(train_files)\n",
    "# run the preprocessing via map\n",
    "train_dataset = train_dataset.map(preprocessing_wrapper, num_parallel_calls=AUTOTUNE)\n",
    "# save dataset to disk\n",
    "#!rm -rf ./_data/processed/train\n",
    "tf.data.experimental.save(dataset=train_dataset, path=f'./_data/processed/train', compression='GZIP')\n",
    "# show tensor types and shapes in dataset (we need this to load the dataset later)\n",
    "print(train_dataset.element_spec)\n",
    "\n",
    "# folder with the evaluation data\n",
    "test_files = '_data/.test/*/*.wav'\n",
    "\n",
    "# define a dataset of file paths\n",
    "test_dataset = tf.data.Dataset.list_files(test_files)\n",
    "# run the preprocessing via map\n",
    "test_dataset = test_dataset.map(preprocessing_wrapper, num_parallel_calls=AUTOTUNE)\n",
    "# save dataset to disk\n",
    "#!rm -rf ./_data/processed/test\n",
    "tf.data.experimental.save(dataset=test_dataset, path=f'./_data/processed/test', compression='GZIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a dataset from disk\n",
    "\n",
    "train_dataset = tf.data.experimental.load(f'./_data/processed/train', \n",
    "                                    (tf.TensorSpec(shape=(config['n_mels'], config['n_frames'], 1), dtype=tf.float32, name=None), \n",
    "                                     tf.TensorSpec(shape=(len(config['classes']),), dtype=tf.uint8, name=None)), \n",
    "                                    compression='GZIP')\n",
    "# keep dataset in memory\n",
    "train_dataset = train_dataset.cache()\n",
    "# shuffle the data\n",
    "train_dataset = train_dataset.shuffle(buffer_size=4000)\n",
    "# batch examples\n",
    "train_dataset = train_dataset.batch(64)\n",
    "# prefetch\n",
    "train_dataset = train_dataset.prefetch(AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.experimental.load(f'./_data/processed/test', \n",
    "                                    (tf.TensorSpec(shape=(config['n_mels'], config['n_frames'], 1), dtype=tf.float32, name=None), \n",
    "                                     tf.TensorSpec(shape=(len(config['classes']),), dtype=tf.uint8, name=None)), \n",
    "                                    compression='GZIP')\n",
    "# keep dataset in memory\n",
    "test_dataset = test_dataset.cache()\n",
    "# batch examples\n",
    "test_dataset = test_dataset.batch(64)\n",
    "# prefetch\n",
    "test_dataset = test_dataset.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 10s 3s/step - loss: 0.7682 - accuracy: 0.4896\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.7126 - accuracy: 0.4919\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.7703 - accuracy: 0.4844\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.7130 - accuracy: 0.4554\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.6917 - accuracy: 0.4933\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.7041 - accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.7084 - accuracy: 0.5200\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.7107 - accuracy: 0.4815\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 6s 2s/step - loss: 0.7003 - accuracy: 0.5067\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 5s 2s/step - loss: 0.6919 - accuracy: 0.5133\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6926 - accuracy: 0.5000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.6925771236419678, 0.5]"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "# create model architecture\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=config['input_shape']))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.GaussianDropout(0.25))\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.GaussianDropout(0.25))\n",
    "model.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.GlobalMaxPool2D())\n",
    "model.add(tf.keras.layers.Dense(len(config['classes']), activation=\"sigmoid\"))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# fit model\n",
    "model.fit(train_dataset, epochs=10)\n",
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}