{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","import json\n","import glob\n","import numpy as np\n","import librosa\n","from librosa import display\n","import matplotlib.pyplot as plt\n","from DLNet_functions import PreprocessWrapper\n","import tensorflow as tf\n","from time import strftime\n","assert tf.__version__ >= \"2.0\"\n","# autotune computation\n","AUTOTUNE = tf.data.experimental.AUTOTUNE"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create Config for preprocessing and pipeline parameters\n","\n","# if true analysis is conducted with mel-spectrograms, if false with \"full\"\n","# spectrograms\n","CALCULATE_MEL = False\n","\n","config: {} = {'sr': 44100,\n","              'audio_length': 1,\n","              'mono': True,\n","              'n_mels': 64,\n","              'n_fft': 1024,\n","              'hop_length': 256,\n","              'win_length': 512,\n","              'window': 'hann',\n","              'center': True,\n","              'pad_mode': 'reflect',\n","              'power': 2.0,\n","              'calculate_mel': CALCULATE_MEL,\n","              'filter_signal': False\n","              }\n","\n","\n","# save number of frames from length in samples divided by fft hop length\n","config['n_frames']: int = int(\n","    config['sr']*config['audio_length']/config['hop_length']) + 1\n","\n","# save input shape for model\n","if CALCULATE_MEL:\n","    config['input_shape']: (int, int, int) = (config['n_mels'], config['n_frames'], 1)\n","else:\n","    config['input_shape']: (int, int, int) = (int(config['n_fft']/2 + 1), config['n_frames'], 1)\n","\n","time_stamp = f'{strftime(\"%d_%m_%Y_%H_%M\")}'\n","# save config\n","with open(f'DLNet_config_{strftime(\"%d_%m_%Y_%H_%M\")}.json', 'w') as fp:\n","    json.dump(config, fp, sort_keys=True, indent=4)\n","\n","# Creater wrapper object:\n","ds_config: str = f'dl4aed_project/Code/_data/dataset_config{time_stamp}.json'\n","wrapper: PreprocessWrapper = PreprocessWrapper(config, ds_config)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create dataset from MedleyDB\n","train_aac, test_aac = wrapper.tf_dataset_from_codec('_data/MedleyDB/compressed_wav/ogg_vbr')\n","train_wav, test_wav = wrapper.tf_dataset_from_codec('_data/MedleyDB/uncompr_wav')\n","test_dataset = test_wav.concatenate(test_aac)\n","train_dataset = train_wav.concatenate(train_aac)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# VISUALIZE WAVEFORMS\n","# get all wav files\n","fps = glob.glob('_data/*_wav/**/*.wav', recursive=True)\n","fps_random = []\n","np.random.seed(9)\n","\n","# setup subplot\n","nrows, ncols = 2, 2\n","fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 6))\n","\n","# plot some audio waveforms\n","for r in range(nrows):\n","    for c in range(ncols):\n","        fp_random = fps[np.random.randint(len(fps))]\n","        audio, sr = librosa.core.load(fp_random, sr=None)\n","        ax[r][c].plot(audio, c='k')\n","        # ax[r][c].axis('off')\n","        ax[r][c].set_title(Path(fp_random).parts[-2:])\n","        if r == 0:\n","            ax[r][c].set_xticks([])\n","        # save random audio filepaths\n","        fps_random.append(fp_random)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# VISUALIZE SPECTROGRAMS\n","# setup subplot\n","nrows, ncols = 4, 2\n","fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 12))\n","\n","# plot some audio waveforms\n","for i, fp_random in enumerate(fps_random):\n","    audio, sr = librosa.core.load(fp_random, sr=None)\n","\n","    # calculate stft\n","    stft = librosa.stft(audio, n_fft=config['n_fft'],\n","                        hop_length=config['hop_length'],\n","                        win_length=config['win_length'])\n","\n","    # calculate melspec\n","    melspec = librosa.feature.melspectrogram(audio, n_fft=config['n_fft'],\n","                                             hop_length=config['hop_length'],\n","                                             n_mels=config['n_mels'],\n","                                             fmax=int(config['sr']/2))\n","    melspec = librosa.amplitude_to_db(melspec, ref=np.max)\n","\n","    # calculate magnitude and scale to dB\n","    magspec = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n","\n","    # plot with librosa\n","    librosa.display.specshow(magspec, x_axis='time', y_axis='linear', sr=sr,\n","                             hop_length=256, ax=ax[i][0])\n","    librosa.display.specshow(melspec, x_axis='time', y_axis='mel', sr=sr,\n","                             hop_length=256, ax=ax[i][1])\n","\n","    # adjustments\n","    # ax[i][1].set_yticks([])\n","    ax[i][1].set_ylabel(Path(fp_random).parts[-2], rotation=270, labelpad=20)\n","    ax[i][1].yaxis.set_label_position(\"right\")\n","\n","    # settings for all axises but bottom ones\n","    if not i == len(fps_random) - 1:\n","        ax[i][0].set_xticks([])\n","        ax[i][1].set_xticks([])\n","        ax[i][0].set_xlabel('')\n","        ax[i][1].set_xlabel('')\n","\n","    # settings for upper axises\n","    if i == 0:\n","        ax[i][0].set_title('stft')\n","        ax[i][1].set_title('mel spectrogram')\n","\n","# adjust whitespace in between subplots\n","plt.subplots_adjust(hspace=0.1, wspace=0.1)\n","\n","print('Melspec shape: %s' % (str(melspec.shape)))\n","print('Stft shape: %s' % (str(stft.shape)))\n","print(f'Total data points in mel-spectrogram: \\\n","      {melspec.shape[0]*melspec.shape[1]}')\n","print(f'Total data points in stft-spectrogram: {stft.shape[0]*stft.shape[1]}')\n","print(f'-> Data Reduction by factor: \\\n","      {(stft.shape[0]*stft.shape[1]) / (melspec.shape[0]*melspec.shape[1])}')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# %% Prepare dataset\n","train_size = len(train_dataset)\n","test_size = len(test_dataset)\n","eval_size = int(.1*train_size)\n","\n","# Shuffel train data:\n","train_dataset = train_dataset.shuffle(buffer_size=train_size)\n","\n","# Split train into train and eval set:\n","eval_dataset = train_dataset.take(eval_size)\n","eval_dataset = eval_dataset.batch(64).prefetch(AUTOTUNE)\n","\n","# Train dataset\n","train_dataset = train_dataset.skip(eval_size)\n","train_dataset = train_dataset.shuffle(train_size - eval_size)\n","train_dataset = train_dataset.batch(64)\n","train_dataset = train_dataset.prefetch(AUTOTUNE)\n","\n","# Prepare test dataset\n","test_dataset = test_dataset.batch(64).prefetch(AUTOTUNE)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# create model architecture\n","model = tf.keras.Sequential()\n","model.add(tf.keras.Input(shape=config['input_shape']))\n","model.add(tf.keras.layers.BatchNormalization())\n","model.add(tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"))\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","model.add(tf.keras.layers.GaussianDropout(0.25))\n","model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","model.add(tf.keras.layers.GaussianDropout(0.25))\n","model.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"))\n","model.add(tf.keras.layers.GlobalMaxPool2D())\n","model.add(tf.keras.layers.Dense(len(config['classes']), activation=\"sigmoid\"))\n","\n","# Define metrics\n","metrics = [tf.keras.metrics.TrueNegatives(),\n","           tf.keras.metrics.TruePositives(),\n","           tf.keras.metrics.FalseNegatives(),\n","           tf.keras.metrics.FalsePositives(),\n","           tf.keras.metrics.Precision(),\n","           tf.keras.metrics.Recall(),\n","           tf.keras.metrics.CategoricalAccuracy()\n","           ]\n","\n","# compile model\n","n_epochs = 10\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# fit model\n","history = model.fit(train_dataset, epochs=n_epochs,\n","                    validation_data=eval_dataset)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# setup plot\n","fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(16,4))\n","\n","# plot loss\n","ax[0].plot(range(n_epochs), history.history['loss'])\n","ax[0].plot(range(n_epochs), history.history['val_loss'])\n","ax[0].set_ylabel('loss'), ax[0].set_title('train_loss vs val_loss')\n","\n","# plot accuracy\n","ax[1].plot(range(n_epochs), history.history['categorical_accuracy'])\n","ax[1].plot(range(n_epochs), history.history['val_categorical_accuracy'])\n","ax[1].set_ylabel('accuracy'), ax[1].set_title('train_acc vs val_acc')\n","\n","# plot adjustement\n","for a in ax:\n","    a.grid(True)\n","    a.legend(['train','val'], loc=4)\n","    a.set_xlabel('num of Epochs')\n","plt.show()\n"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3.8.6 64-bit ('dl4aed': conda)","metadata":{"interpreter":{"hash":"228ad9cca5d97dd7d9557fa2cd16f7b4b17e3fd9f84af46b9b58ef7f9e569100"}}}}}