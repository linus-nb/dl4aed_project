{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from pathlib import Path\n","import json\n","import glob\n","import numpy as np\n","import librosa\n","from librosa import display\n","import matplotlib.pyplot as plt\n","from DLNet_functions import preprocess_wrapper\n","import tensorflow as tf\n","assert tf.__version__ >= \"2.0\"\n","# autotune computation\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Create Config for preprocessing and pipeline parameters\n","\n","config = {'sr': 44100,\n","          'audio_length': 1,\n","          'mono': True,\n","          'n_mels': 64,\n","          'n_fft': 1024,\n","          'hop_length': 256,\n","          'win_length': 512,\n","          'window': 'hann',\n","          'center': True,\n","          'pad_mode': 'reflect',\n","          'power': 2.0,\n","          }\n","\n","# save classes from foldernames\n","# folders = glob.glob('_data/*_wav/')\n","# config['classes'] = sorted(set([Path(f).parts[-1] for f in folders]))\n","config['classes'] = ['compressed_wav', 'uncompr_wav']\n","\n","# save number of frames from length in samples divided by fft hop length\n","config['n_frames'] = int(\n","    config['sr']*config['audio_length']/config['hop_length']) + 1\n","\n","# save input shape for model\n","config['input_shape'] = (config['n_mels'], config['n_frames'], 1)\n","\n","# save config\n","with open('DLNet_config.json', 'w+') as fp:\n","    json.dump(config, fp, sort_keys=True, indent=4)\n","\n","# Creater wrapper object:\n","ds_config = 'dl4aed_project/Code/_data/dataset_config.json'\n","wrapper = preprocess_wrapper(config, ds_config)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: _data/compressed_wav/mp3_32k/*.wav'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m~/tubCloud/Documents/3.Semester/DL4AED/dl4aed_project/Code/DLNet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     dirs = ['_data/compressed_wav/mp3_32k',\n\u001b[1;32m      7\u001b[0m             '_data/uncompr_wav']\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_tf_dataset_from_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Load dataset:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/tubCloud/Documents/3.Semester/DL4AED/dl4aed_project/Code/DLNet_functions.py\u001b[0m in \u001b[0;36mgen_tf_dataset_from_list\u001b[0;34m(self, dirs, save, ds_name)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msave\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mds_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Name must be given, if dataset is saved.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_tf_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# For list of dirs:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/tubCloud/Documents/3.Semester/DL4AED/dl4aed_project/Code/DLNet_functions.py\u001b[0m in \u001b[0;36mgen_tf_dataset\u001b[0;34m(self, directory, save)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mAUTOTUNE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# define a dataset of file paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;31m# run the preprocessing via map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         dataset = dataset.map(self.preprocessing_wrapper,\n","\u001b[0;32m~/miniconda3/envs/dl4aed/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mlist_files\u001b[0;34m(file_pattern, shuffle, seed)\u001b[0m\n\u001b[1;32m   1222\u001b[0m           string_ops.reduce_join(file_pattern, separator=\", \"), name=\"message\")\n\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m       assert_not_empty = control_flow_ops.Assert(\n\u001b[0m\u001b[1;32m   1225\u001b[0m           condition, [message], summarize=1, name=\"assert_not_empty\")\n\u001b[1;32m   1226\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massert_not_empty\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/dl4aed/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/dl4aed/lib/python3.8/site-packages/tensorflow/python/util/tf_should_use.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;34m\"\"\"Decorates the input function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m       return _add_should_use_warning(fn(*args, **kwargs),\n\u001b[0m\u001b[1;32m    248\u001b[0m                                      \u001b[0mwarn_in_eager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_in_eager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                                      error_in_function=error_in_function)\n","\u001b[0;32m~/miniconda3/envs/dl4aed/lib/python3.8/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAssert\u001b[0;34m(condition, data, summarize, name)\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_n_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m       \u001b[0mdata_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_summarize_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m       raise errors.InvalidArgumentError(\n\u001b[0m\u001b[1;32m    155\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: _data/compressed_wav/mp3_32k/*.wav'"]}],"source":["# Generate datasets (true) or load datasets (false):\n","generate = True\n","if generate:\n","    # Generate mp3_32k dataset and uncompressed wav dataset from dirs\n","    # this dataset will not be saved!\n","    dirs = ['_data/compressed_wav/mp3_32k',\n","            '_data/uncompr_wav']\n","    dataset = wrapper.gen_tf_dataset_from_list(dirs)\n","else:\n","    # Load dataset:\n","    dataset_1 = wrapper.load_tf_dataset('_data/dataset_mp3_32k')\n","    dataset_2 = wrapper.load_tf_dataset('_data/dataset_uncompr_wav')\n","    dataset = dataset_2.concatenate(dataset_1)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# VISUALIZE WAVEFORMS\n","# get all wav files\n","fps = glob.glob('_data/*_wav/**/*.wav', recursive=True)\n","fps_random = []\n","np.random.seed(9)\n","\n","# setup subplot\n","nrows, ncols = 2, 2\n","fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 6))\n","\n","# plot some audio waveforms\n","for r in range(nrows):\n","    for c in range(ncols):\n","        fp_random = fps[np.random.randint(len(fps))]\n","        audio, sr = librosa.core.load(fp_random, sr=None)\n","        ax[r][c].plot(audio, c='k')\n","        # ax[r][c].axis('off')\n","        ax[r][c].set_title(Path(fp_random).parts[-2:])\n","        if r == 0:\n","            ax[r][c].set_xticks([])\n","        # save random audio filepaths\n","        fps_random.append(fp_random)\n",""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'melspec' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m~/tubCloud/Documents/3.Semester/DL4AED/dl4aed_project/Code/DLNet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Melspec shape: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Stft shape: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m print(f'Total data points in mel-spectrogram: \\\n","\u001b[0;31mNameError\u001b[0m: name 'melspec' is not defined"]}],"source":["# VISUALIZE SPECTROGRAMS\n","# setup subplot\n","nrows, ncols = 4, 2\n","fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(16, 12))\n","\n","# plot some audio waveforms\n","for i, fp_random in enumerate(fps_random):\n","    audio, sr = librosa.core.load(fp_random, sr=None)\n","\n","    # calculate stft\n","    stft = librosa.stft(audio, n_fft=config['n_fft'],\n","                        hop_length=config['hop_length'],\n","                        win_length=config['win_length'])\n","\n","    # calculate melspec\n","    melspec = librosa.feature.melspectrogram(audio, n_fft=config['n_fft'],\n","                                             hop_length=config['hop_length'],\n","                                             n_mels=config['n_mels'],\n","                                             fmax=int(config['sr']/2))\n","    melspec = librosa.amplitude_to_db(melspec, ref=np.max)\n","\n","    # calculate magnitude and scale to dB\n","    magspec = librosa.amplitude_to_db(np.abs(stft), ref=np.max)\n","\n","    # plot with librosa\n","    librosa.display.specshow(magspec, x_axis='time', y_axis='linear', sr=sr,\n","                             hop_length=256, ax=ax[i][0])\n","    librosa.display.specshow(melspec, x_axis='time', y_axis='mel', sr=sr,\n","                             hop_length=256, ax=ax[i][1])\n","\n","    # adjustments\n","    # ax[i][1].set_yticks([])\n","    ax[i][1].set_ylabel(Path(fp_random).parts[-2], rotation=270, labelpad=20)\n","    ax[i][1].yaxis.set_label_position(\"right\")\n","\n","    # settings for all axises but bottom ones\n","    if not i == len(fps_random) - 1:\n","        ax[i][0].set_xticks([])\n","        ax[i][1].set_xticks([])\n","        ax[i][0].set_xlabel('')\n","        ax[i][1].set_xlabel('')\n","\n","    # settings for upper axises\n","    if i == 0:\n","        ax[i][0].set_title('stft')\n","        ax[i][1].set_title('mel spectrogram')\n","\n","# adjust whitespace in between subplots\n","plt.subplots_adjust(hspace=0.1, wspace=0.1)\n","\n","print('Melspec shape: %s' % (str(melspec.shape)))\n","print('Stft shape: %s' % (str(stft.shape)))\n","print(f'Total data points in mel-spectrogram: \\\n","      {melspec.shape[0]*melspec.shape[1]}')\n","print(f'Total data points in stft-spectrogram: {stft.shape[0]*stft.shape[1]}')\n","print(f'-> Data Reduction by factor: \\\n","      {(stft.shape[0]*stft.shape[1]) / (melspec.shape[0]*melspec.shape[1])}')\n","\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Split dataset in 80:20 (test:train)\n","buff_size = len(dataset)\n","train_size = int(.8*buff_size)\n","test_size = buff_size - train_size\n","# shuffle before splitting in train and eval dataset\n","dataset = dataset.shuffle(buffer_size=buff_size)\n","dataset = dataset.cache()\n","\n","# take first 80% from dataset\n","train_dataset = dataset.take(train_size)\n","train_dataset = train_dataset.shuffle(buffer_size=train_size)\n","train_dataset = train_dataset.batch(64)\n","train_dataset = train_dataset.prefetch(AUTOTUNE)\n","\n","# take last 20% samples from dataset\n","test_dataset = dataset.skip(test_size).shuffle(test_size)\n","test_dataset = test_dataset.batch(64).prefetch(AUTOTUNE)\n","eval_dataset = test_dataset\n",""]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train_dataset' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m~/tubCloud/Documents/3.Semester/DL4AED/dl4aed_project/Code/DLNet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# fit model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m history = model.fit(train_dataset, epochs=n_epochs,\n\u001b[0m\u001b[1;32m     33\u001b[0m                     validation_data=eval_dataset)\n","\u001b[0;31mNameError\u001b[0m: name 'train_dataset' is not defined"]}],"source":["# create model architecture\n","model = tf.keras.Sequential()\n","model.add(tf.keras.Input(shape=config['input_shape']))\n","model.add(tf.keras.layers.BatchNormalization())\n","model.add(tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\"))\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","model.add(tf.keras.layers.GaussianDropout(0.25))\n","model.add(tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"))\n","model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n","model.add(tf.keras.layers.GaussianDropout(0.25))\n","model.add(tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\"))\n","model.add(tf.keras.layers.GlobalMaxPool2D())\n","model.add(tf.keras.layers.Dense(len(config['classes']), activation=\"sigmoid\"))\n","\n","# Define metrics\n","metrics = [tf.keras.metrics.TrueNegatives(),\n","           tf.keras.metrics.TruePositives(),\n","           tf.keras.metrics.FalseNegatives(),\n","           tf.keras.metrics.FalsePositives(),\n","           tf.keras.metrics.Precision(),\n","           tf.keras.metrics.Recall(),\n","           tf.keras.metrics.CategoricalAccuracy()\n","           ]\n","\n","# compile model\n","n_epochs = 10\n","model.compile(optimizer='adam',\n","              loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# fit model\n","history = model.fit(train_dataset, epochs=n_epochs,\n","                    validation_data=eval_dataset)\n",""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# setup plot\n","fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(16,4))\n","\n","# plot loss\n","ax[0].plot(range(n_epochs), history.history['loss'])\n","ax[0].plot(range(n_epochs), history.history['val_loss'])\n","ax[0].set_ylabel('loss'), ax[0].set_title('train_loss vs val_loss')\n","\n","# plot accuracy\n","ax[1].plot(range(n_epochs), history.history['categorical_accuracy'])\n","ax[1].plot(range(n_epochs), history.history['val_categorical_accuracy'])\n","ax[1].set_ylabel('accuracy'), ax[1].set_title('train_acc vs val_acc')\n","\n","# plot adjustement\n","for a in ax:\n","    a.grid(True)\n","    a.legend(['train','val'], loc=4)\n","    a.set_xlabel('num of Epochs')\n","plt.show()\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}