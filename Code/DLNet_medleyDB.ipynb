{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "colab": {
      "name": "DLNet.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gd2EjmDhoEl"
      },
      "source": [
        "### Mount drive to datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2kZTqtHPXRH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd6780ca-e333-4618-c82e-785f3a93fd9e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KDqTnB4hu15"
      },
      "source": [
        "### Import libraries and set `DATA_PATH`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y0MuZpvPSoG",
        "outputId": "2d62fe23-e69c-4a50-f27c-3ee2bf061a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "import glob\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "from librosa import display\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from time import strftime\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "# autotune computation\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "DATA_PATH = '/content/drive/MyDrive'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-026054f43ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlibrosa\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mDLNet_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreprocessWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstrftime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'DLNet_functions'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yn_Zm1eh7Rd"
      },
      "source": [
        "### All paths to possible codecs:\n",
        "All codec datasets are created for a binary problem. <br>\n",
        "See configs in DLNet_config.json for details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwA9IoGvXyT0"
      },
      "source": [
        "# Path to datasets:\n",
        "# Full dataset (with all codecs)\n",
        "path_medley_train = os.path.join(DATA_PATH, 'tf_dataset_MedleyDB_small', 'MedleyDB_train_set')\n",
        "path_medley_test = os.path.join(DATA_PATH, 'tf_dataset_MedleyDB_small', 'MedleyDB_test_set')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im76779riuFO"
      },
      "source": [
        "### Read `config` and create `wrapper` object:\n",
        "Each dataset has a config file included with the dataset configurations.<br>\n",
        "Dataset configurations have to match to concatenate the datasets later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U5gsogwPSoL"
      },
      "source": [
        " # Read configs from dataset:\n",
        "json_file_codec =  os.path.join(os.path.split(path_medley_train)[0], 'DLNet_config.json')\n",
        "with open(json_file_codec, \"r\") as read_file:\n",
        "            config = json.load(read_file)\n",
        "        \n",
        "# Path to dataset_config:\n",
        "ds_config: str = os.path.join(DATA_PATH, 'dataset_config.json')\n",
        "# Creater wrapper object:\n",
        "wrapper: PreprocessWrapper = PreprocessWrapper(config, ds_config)\n",
        "# Print Config:\n",
        "print(json.dumps(config, sort_keys=False, indent=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM8gxj4ajdqQ"
      },
      "source": [
        "### Load chosen datasets and concatenate them:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeMDGkRMXjHP"
      },
      "source": [
        "# Load dataset:\n",
        "# Codec1: (Compressed)\n",
        "train_dataset = wrapper.load_tf_dataset(path_medley_train)\n",
        "test_dataset = wrapper.load_tf_dataset(path_medley_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml1i2p3tjnOP"
      },
      "source": [
        "### Print dataset info:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR9MpUUkc1Wr"
      },
      "source": [
        "print(train_dataset)\n",
        "print(len(train_dataset))\n",
        "print(test_dataset)\n",
        "print(len(test_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6L60LYGj19d"
      },
      "source": [
        "### Prepare datasets:\n",
        "\n",
        "\n",
        "*   Shuffle `train_dataset`\n",
        "*   Take 10 % of `train_dataset` for evaluation: `eval_dataset`\n",
        "*   Shuffle and batch rest of `train_dataset`\n",
        "*   Batch `test_dataset`\n",
        "*   Batch size: 64\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocaBr3OiPSoO"
      },
      "source": [
        "train_size = len(train_dataset)\n",
        "test_size = len(test_dataset)\n",
        "eval_size = int(.1*train_size)\n",
        "batch_size = 64\n",
        "\n",
        "# Shuffel train data:\n",
        "train_dataset = train_dataset.shuffle(buffer_size=int(train_size/3))\n",
        "\n",
        "# Split train into train and eval set:\n",
        "eval_dataset = train_dataset.take(eval_size)\n",
        "eval_dataset = eval_dataset.batch(batch_size).prefetch(AUTOTUNE)\n",
        "\n",
        "# Train dataset\n",
        "train_dataset = train_dataset.skip(eval_size)\n",
        "train_dataset = train_dataset.shuffle(train_size - eval_size)\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "train_dataset = train_dataset.prefetch(AUTOTUNE)\n",
        "\n",
        "# Prepare test dataset\n",
        "test_dataset = test_dataset.batch(batch_size).prefetch(AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekQWRjrOkqjJ"
      },
      "source": [
        "### Create and compile CNN Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zum-gT5ZRIX3"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.Input(shape=config['input_shape']))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.GlobalMaxPool2D())\n",
        "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.GaussianDropout(0.25))\n",
        "model.add(tf.keras.layers.Dense(256, activation=\"relu\"))\n",
        "model.add(tf.keras.layers.GaussianDropout(0.25))\n",
        "model.add(tf.keras.layers.Dense(len(config['classes']), activation=\"softmax\"))\n",
        "\n",
        "# Define metrics\n",
        "metrics = [tf.keras.metrics.TrueNegatives(),\n",
        "           tf.keras.metrics.TruePositives(),\n",
        "           tf.keras.metrics.FalseNegatives(),\n",
        "           tf.keras.metrics.FalsePositives(),\n",
        "           tf.keras.metrics.Precision(),\n",
        "           tf.keras.metrics.Recall(),\n",
        "           tf.keras.metrics.CategoricalAccuracy()\n",
        "           ]\n",
        "\n",
        "# compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avCQK_89ksTr"
      },
      "source": [
        "### Train and evaluate model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vC-5lFN0PSoP"
      },
      "source": [
        "# fit model\n",
        "n_epochs = 20\n",
        "history = model.fit(train_dataset, epochs=n_epochs,\n",
        "                    validation_data=eval_dataset, verbose=1)\n",
        "\n",
        "model.evaluate(test_dataset, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDJAlyLJPSoQ"
      },
      "source": [
        "# setup plot\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2,figsize=(16,4))\n",
        "\n",
        "# plot loss\n",
        "ax[0].plot(range(n_epochs), history.history['loss'])\n",
        "ax[0].plot(range(n_epochs), history.history['val_loss'])\n",
        "ax[0].set_ylabel('loss'), ax[0].set_title('train_loss vs val_loss')\n",
        "\n",
        "# plot accuracy\n",
        "ax[1].plot(range(n_epochs), history.history['accuracy'])\n",
        "ax[1].plot(range(n_epochs), history.history['val_accuracy'])\n",
        "ax[1].set_ylabel('accuracy'), ax[1].set_title('train_acc vs val_acc')\n",
        "\n",
        "# plot adjustement\n",
        "for a in ax:\n",
        "    a.grid(True)\n",
        "    a.legend(['train','val'], loc=4)\n",
        "    a.set_xlabel('num of Epochs')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5m9mk8wqf4m4"
      },
      "source": [
        "### Model prediction as numpy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2y1aUZVf2EQ"
      },
      "source": [
        "y_test_prob = model.predict(test_dataset)\n",
        "y_test_pred = np.argmax(y_test_prob, axis=1)\n",
        "y_test_true = np.argmax(np.array([y for x, y in test_dataset.unbatch().as_numpy_iterator()]), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGiNGBUI6AY6"
      },
      "source": [
        "# Check label distribution in test set:\n",
        "plt.hist(y_test_true, align='left')\n",
        "plt.xticks([0, 1, 2, 3, 4, 5, 6], config['classes'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMeUYne-fLin"
      },
      "source": [
        "### Print metrics with sklearn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeN50E41e-QT"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print('Classification report:')\n",
        "print(classification_report(y_true=y_test_true, y_pred=y_test_pred,\n",
        "                            target_names=config['classes']))\n",
        "\n",
        "print('------------------------------------------------:')\n",
        "print('Evaluate model on test dataset:')\n",
        "hist_eval = model.evaluate(test_dataset)\n",
        "\n",
        "print('------------------------------------------------:')\n",
        "print('Evaluate model on eval dataset:')\n",
        "hist_eval = model.evaluate(eval_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0QHbCHVfRYM"
      },
      "source": [
        "### Confusion Matrix:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeHmGGaWdKla"
      },
      "source": [
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label'), plt.xlabel('Predicted label')\n",
        "\n",
        "# call confusion matrix\n",
        "cm = tf.math.confusion_matrix(labels=y_test_true, predictions=y_test_pred)\n",
        "cm = cm.numpy()\n",
        "plot_confusion_matrix(cm, classes=config['classes'], normalize=False,\n",
        "                      title='Confusion matrix', cmap=plt.cm.Blues)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}